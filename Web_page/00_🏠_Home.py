import streamlit as st
import pickle
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from PIL import Image
st.set_page_config(
    page_title="Home",
    page_icon="üè†",
    layout="wide",
)
#Importing necesssary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Ignore warnings
import warnings 
from warnings import filterwarnings
filterwarnings("ignore")

#Importing SHAP(XAI)
from streamlit_shap import st_shap
import shap
shap.initjs()

password = Image.open(r"C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Images\password.jpg")
st.image(password, width=100)
st.write("# Predict Password Strength üîí")

# T·∫£i m√¥ h√¨nh ƒë√£ l∆∞u
with open(r'C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Models\rf.pkl', 'rb') as file:
    rf = pickle.load(file)

# T·∫£i m√¥ h√¨nh ƒë√£ l∆∞u
with open(r'C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Models\vectorizer.pkl', 'rb') as file:
    vectorizer = pickle.load(file)

with open(r'C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Variable\X_test.pkl', 'rb') as file:
    X_test = pickle.load(file)
with open(r'C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Variable\X_train.pkl', 'rb') as file:
    X_train = pickle.load(file)
with open(r'C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Variable\y_train.pkl', 'rb') as file:
    y_train = pickle.load(file)
with open(r'C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Variable\y_test.pkl', 'rb') as file:
    y_test = pickle.load(file)
with open(r'C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Variable\y_pred.pkl', 'rb') as file:
    y_pred = pickle.load(file)
with open(r'C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Variable\explainer.pkl', 'rb') as file:
    explainer = pickle.load(file)
with open(r'C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Variable\shap_values.pkl', 'rb') as file:
    shap_values = pickle.load(file)
with open(r'C:\Users\asus\OneDrive - Tr∆∞·ªùng ƒêH CNTT - University of Information Technology\VISUAL STUDIO CODE\PYTHON\IE105\Streamlit IE105\Web_page\Variable\feature_names.pkl', 'rb') as file:
    feature_names = pickle.load(file)

#H√†m d·ª± ƒëo√°n m·∫≠t kh·∫©u
def predict(password):
    # Bi·∫øn ƒë·ªïi m·∫≠t kh·∫©u th√†nh ma tr·∫≠n ƒë·∫∑c tr∆∞ng
    sample_array = np.array([password])
    sample_matrix = vectorizer.transform(sample_array) 
    
    # T√≠nh to√°n c√°c ƒë·∫∑c tr∆∞ng b·ªï sung
    length_pass = len(password)
    length_normalised_lowercase = len([char for char in password if char.islower()]) / len(password)
    
    new_matrix2 = np.append(sample_matrix.toarray(), (length_pass, length_normalised_lowercase)).reshape(1, 101)
    
    # D·ª± ƒëo√°n k·∫øt qu·∫£
    result = rf.predict(new_matrix2)
    predicted_strength = ["weak", "normal", "strong"][result[0]]
    
    # T√≠nh to√°n gi√° tr·ªã SHAP ƒë·ªÉ gi·∫£i th√≠ch
    shap_values = explainer.shap_values(new_matrix2)
    #explanation = shap.force_plot(explainer.expected_value[result[0]], shap_values[:,:,result[0]][0], feature_names, matplotlib=True)
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ v√† gi·∫£i th√≠ch
    st.write(f"Password strength prediction: {predicted_strength}")
    st.write("Explanation of the prediction:")
    #st_shap(explanation)
    
    #return predicted_strength
     # Gi·∫£i th√≠ch b·∫±ng force plot
    st.write("Force Plot (Feature Impact)")
    force_plot = shap.force_plot(
        explainer.expected_value[result[0]], 
        shap_values[:,:,result[0]][0], 
        feature_names, 
        matplotlib=True
    )
    st_shap(force_plot)
    
    # Gi·∫£i th√≠ch b·∫±ng summary plot
    st.write("Summary Plot (Global Feature Importance)")
    summary_plot = shap.summary_plot(
        shap_values[:,:,result[0]], 
        new_matrix2, 
        feature_names=feature_names,
        plot_type="bar"
    )
    st_shap(summary_plot)

# Nh·∫≠p d·ªØ li·ªáu t·ª´ ng∆∞·ªùi d√πng
text = st.text_input("Enter a password:")

# Th√™m n√∫t ƒë·ªÉ th·ª±c hi·ªán d·ª± ƒëo√°n
if st.button("Predict Password Strength"):
    if text:  # Ki·ªÉm tra n·∫øu ng∆∞·ªùi d√πng ƒë√£ nh·∫≠p d·ªØ li·ªáu
        predict(text)
    else:
        st.write("Please input a value.")

st.sidebar.success("Select for more details.")

st.markdown(
    """
    - Strength of password is a vital task in understanding the security level of passwords. 
    
    - In this project, we employ SHAP to explain the model we used to analysis password strength based on their sentiment. 
    - The objective is to build accurate models that can automatically predict whether password is weak, normal or strong.

    **üëà Select for more details from the sidebar** to see some examples
    ### About our dataset
    - Check out [Kaggle üíæ](https://www.kaggle.com/datasets/soylevbeytullah/password-datas)

    - This dataset having 100k passwords for natural language processing or Text analytics.
    - This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. 
    - We provide a set of 80,000 datasets for training and 20,000 for testing. 
    - So, predict by using LogisticRegression, DecisionTree, RandomForest, SupportVectorMachine, NeuralNetworking.
    - The best model is RandomForest with 0.92 accuracy.
"""
)